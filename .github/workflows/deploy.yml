name: Deploy Recipe Sharing App Serverless Stack

on:
  push:
    branches: [ main ]
  workflow_dispatch:  # allows manual trigger from GitHub UI

env:
  AWS_REGION: eu-central-1
  LAMBDAS_BUCKET_NAME: recipe-sharing-lambdas-${{ github.run_id }}

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4.2.2

      - name: Set up AWS CLI
        uses: aws-actions/configure-aws-credentials@v4.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Ensure S3 bucket exists for Lambda codes
        run: |
          # Check if the bucket already exists. If it doesn't, create it.
          aws s3api head-bucket --bucket $LAMBDAS_BUCKET_NAME || \
          aws s3api create-bucket --bucket $LAMBDAS_BUCKET_NAME --region $AWS_REGION \
            --create-bucket-configuration LocationConstraint=$AWS_REGION

      - name: Package all Lambda functions
        run: |
          mkdir -p artifacts
          
          # Each immediate sub-folder of /lambdas is treated as ONE Lambda  ➜  one .zip
          for dir in 05_Recipe_Sharing_App_Serverless_Edition/lambdas/*/ ; do
            fn_name=$(basename "$dir")
          
            # Skip empty folders so the job doesnt fail on half-finished work
            if [ "$(find "$dir" -type f | wc -l)" -eq 0 ]; then
              echo "⚠️ Skipping $fn_name - no files inside."
              continue
            fi
          
            echo "📦  Zipping $fn_name …"
          
            (
              cd "$dir"                    
              zip -qr "../../artifacts/${fn_name}.zip" .  
            )
          done

      - name: Upload all lambda artifacts to S3
        run: |
          # Upload all the zip files to the S3 bucket
          for file in artifacts/*.zip
          do
            aws s3 cp "$file" "s3://$LAMBDAS_BUCKET_NAME/lambdas/"
          done

      - name: Deploy CloudFormation
        run: |
          aws cloudformation deploy \
          --template-file 05_Recipe_Sharing_App_Serverless_Edition/CFN-Template.yaml \
          --stack-name recipe-sharing \
          --capabilities CAPABILITY_IAM \
          --parameter-overrides "LambdasBucketName=$LAMBDAS_BUCKET_NAME"

      - name: Build and Deploy Frontend
        run: |
          # Get the cf template outputs
          aws cloudformation describe-stacks --stack-name recipe-sharing --query "Stacks[0].Outputs" --output json > outputs.json
          
          # Extract the necessary output values
          HttpApiEndpoint=$(jq -r '.[] | select(.OutputKey=="HttpApiEndpoint") | .OutputValue' outputs.json)
          UserPoolId=$(jq -r '.[] | select(.OutputKey=="UserPoolId") | .OutputValue' outputs.json)
          UserPoolClientId=$(jq -r '.[] | select(.OutputKey=="UserPoolClientId") | .OutputValue' outputs.json)
          CognitoRegion=$(jq -r '.[] | select(.OutputKey=="CognitoRegion") | .OutputValue' outputs.json)
          CloudFrontDistributionUrl=$(jq -r '.[] | select(.OutputKey=="CloudFrontDistributionUrl") | .OutputValue' outputs.json)

          # Replace the placeholders in the frontend config files
          CONFIGS_FILE=05_Recipe_Sharing_App_Serverless_Edition/frontend/src/configs/configs.tsx
          AWS_EXPORTS_FILE=05_Recipe_Sharing_App_Serverless_Edition/frontend/src/configs/aws-exports.ts
          sed -i "s|YOUR_API_URL|$HttpApiEndpoint|" $CONFIGS_FILE
          sed -i "s|CognitoRegion|$CognitoRegion|g" $AWS_EXPORTS_FILE
          sed -i "s|UserPoolId|$UserPoolId|" $AWS_EXPORTS_FILE
          sed -i "s|UserPoolClientId|$UserPoolClientId|" $AWS_EXPORTS_FILE
          
          # Build the frontend
          cd 05_Recipe_Sharing_App_Serverless_Edition/frontend
          npm ci
          npm run build

          # Sync the build output to the S3 bucket
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          aws s3 sync dist/ s3://recipesharing-frontend-$ACCOUNT_ID --delete     # Uploads only changed files 

          # Optionally, invalidate CloudFront cache
          # aws cloudfront create-invalidation --distribution-id YOUR_DISTRIBUTION_ID --paths "/*"

      - name: Clean up
        if: always()  # This step will run even if the previous steps fail
        run: |
          # Remove the artifacts directory
          rm -rf artifacts
          # Optionally, delete the S3 bucket if you want to clean up after deployment
          aws s3 rb s3://$LAMBDAS_BUCKET_NAME --force
          
